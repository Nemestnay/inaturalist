import os
import shutil
import pandas as pd
import numpy as np

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.mobilenet_v2 import preprocess_input
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D


from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True


import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns


plt.rcParams['figure.figsize'] = 12, 8
plt.rcParams.update({'font.size': 12})


AUTOTUNE = tf.data.experimental.AUTOTUNE
IMG_SIZE = 299
BATCH_SIZE = 32


data_path = '/home/alena/Рабочий стол/Уник/наука о данных/inaturalist/images'


for subfolder in ['желтоносая', 'пестроносая',]:
    original_path = f'{data_path}/{subfolder}'
    original_data = os.listdir(original_path)

    n_samples = len(original_data)
    train_samples = int(n_samples * 0.75)
    valid_samples = int(n_samples * 0.1)

    train_path = os.path.join('train', subfolder)
    valid_path = os.path.join('valid', subfolder)
    test_path = os.path.join('test', subfolder)
    
    # Create class subfolders for training, validation, and testing:
    os.makedirs(train_path, exist_ok=True)
    os.makedirs(valid_path, exist_ok=True)
    os.makedirs(test_path, exist_ok=True)

    # Training images:
    for image in original_data[:train_samples]:
        original_file = os.path.join(original_path, image)
        new_file = data_path +'/train/'+ str(subfolder) + '/' + image
        shutil.copyfile(original_file, new_file)

    # Validation images:
    for image in original_data[train_samples:train_samples + valid_samples]:
        original_file = os.path.join(original_path, image)
        new_file = data_path +'/valid/'+ str(subfolder) + '/' + image
        shutil.copyfile(original_file, new_file)

    # Test images:
    for image in original_data[train_samples + valid_samples:]:
        original_file = os.path.join(original_path, image)
        new_file = data_path +'/test/'+ str(subfolder) + '/' + image
        shutil.copyfile(original_file, new_file)


print('train dataset')
train_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\
                    .flow_from_directory(directory= data_path + '/train',
                                         target_size=(IMG_SIZE, IMG_SIZE),
                                         class_mode='categorical',
                                         batch_size=BATCH_SIZE,
                                         shuffle=True)
print('valid dataset')
valid_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\
                    .flow_from_directory(directory='/home/alena/Рабочий стол/Уник/наука о данных/inaturalist/images/valid',
                                         target_size=(IMG_SIZE, IMG_SIZE), 
                                         class_mode='categorical',
                                         batch_size=BATCH_SIZE,
                                         shuffle=True)
print('test dataset')
test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\
                    .flow_from_directory(directory='/home/alena/Рабочий стол/Уник/наука о данных/inaturalist/images/test',
                                         target_size=(IMG_SIZE, IMG_SIZE),
                                         class_mode='categorical',
                                         batch_size=BATCH_SIZE,
                                         shuffle=True)


base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
base_model.trainable = False
base_model.summary()


global_average_layer = GlobalAveragePooling2D()
prediction_layer = Dense(2, activation='softmax')
model = tf.keras.Sequential([
  base_model,
  global_average_layer,
  prediction_layer
])


base_learning_rate = 0.0001
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()


epochs_num = 20
history = model.fit(train_generator, validation_data=valid_generator,
                    epochs=epochs_num, steps_per_epoch=20, validation_steps=10)


acc = history.history['accuracy']
loss = history.history['loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc)
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss)
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training Loss')
plt.xlabel('epoch')
plt.show()


loss, accuracy = model.evaluate(test_generator, steps=10, verbose=2)
print(f'Model performance on test images:\nAccuracy = {accuracy}\nLoss = {loss}')


y_pred = model.predict(test_generator)
y_true = test_generator.classes
y_pred_classes = tf.argmax(y_pred, axis=1).numpy()


conf_matrix = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices, yticklabels=test_generator.class_indices)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()


import random

random_index = random.randint(0, len(test_generator) - 1)
random_image, random_label = test_generator[random_index]
plt.imshow(random_image[0])
image_class = y_pred_classes[random_index]
mapping = {0:    'желтоносая',
           1:    'пестроносая'}
plt.title(f'Predicted: {mapping[image_class]}, Real: {mapping[np.argmax(random_label[0])]}')
